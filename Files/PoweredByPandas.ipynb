{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Powered by Pandas\n",
    "**Authors:** Raymond Tran, Edel Grace Altares<br/>\n",
    "**Audience:** New programmers w/ a basic understanding of Python, procedural, and object-oriented programming.\n",
    "\n",
    "Welcome to Powered by Pandas! This workbook is designed to introduce its audience to a little bit of the `pandas` and `matplotlib` Python libraries. The code is thoroughly documented and explained with section headings that give a general idea of what will be explained in a few chunks of code.\n",
    "\n",
    "**Useful Things in Jupyter:**<br/>\n",
    "- **Shift + Enter** allows you to execute the currently selected cell, and immediately moves the pointer to the next one for you.\n",
    "- **Pressing Tab** immediately after a `.` in a line of code like `object.` will showcase all the methods/functions that can be used with that particular class. Note that `pandas` and `matplotlib` have *a lot*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting Started\n",
    "When Jupyter is installed with Anaconda Navigator, many data analysis modules come with it.\n",
    "\n",
    "Some other modules that won't be featured include:\n",
    "- **seaborn**  (A prettier, fancier data visualizer with its own set of features.)\n",
    "- **networkx** (Graph/Network modelling and manipulation.)\n",
    "- **scipy**    (A scientific computing library for stuff like optimization, linear algebra, and so on.)\n",
    "- **sklearn**  (A library for data classification and machine learning!)\n",
    "- **numpy**    (A module that expands on the concept of arrays that are fast, efficient, and flexible. Numpy arrays are used in pandas internally.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a module, but refer to it as something else in the code.\n",
    "# For example, instead of calling pandas every time, just call it pd.\n",
    "# And, let it know that you don't need to refer to the parent 'pd' every time when playing with DataFrames and Series.\n",
    "# Without 'from pandas import DataFrame, Series' = pd.DataFrame.head\n",
    "# With 'from pandas import DataFrame, Series' = Data.head\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## File IO, DataFrames, and You!\n",
    "\n",
    "Let's start off by opening a small csv spreadsheet that contains some people, their favourite fruits, and what year in university they are!<br/>\n",
    "To see what file-types are supported, you can check: [Pandas Doc - IO](https://pandas.pydata.org/pandas-docs/stable/io.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Import.\n",
    "quickDF = pd.read_clipboard()\n",
    "quickDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame called csvDF.\n",
    "# Then, fill it with the contents of the file.\n",
    "csvFileName = \"fruitsAndPeople.csv\"\n",
    "csvDF = pd.read_csv(csvFileName)\n",
    "csvDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframes are made up of a bunch of 'Series'** Similar to how matrices are made up of lists.<br/>\n",
    "We can also add rows and columns of data, merge DataFrames, etc.<br/>\n",
    "We'll show this by adding a new entry to the frame, as well as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a row of data. \n",
    "newRow1 = {'Name': 'Joe',\n",
    "          'Fav Fruit': 'Watermelon', \n",
    "          'Yr. of Study': 4,\n",
    "          'Plays Music': True}\n",
    "\n",
    "# Create a new DataFrame, and put the row of data into it using append()\n",
    "mergeDF = DataFrame()\n",
    "# Ignore Index prevents duplicate index values by ensuring a new, unique one is assigned.\n",
    "mergeDF = mergeDF.append(newRow1, ignore_index=True)\n",
    "\n",
    "# We can also merge two dataframes like so:\n",
    "csvDF = csvDF.append(mergeDF, ignore_index=True, sort=False)\n",
    "#csvDF = csvDF[['Name','Fav Fruit','Yr. of Study','Plays Music']] # Sort the columns by how we know them. (Deprecated line.)\n",
    "csvDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column of data.\n",
    "# Locate the row (nothing), and the column (Total).\n",
    "# If the column doesn't exist, the DataFrame will create a new one and initialize it with the values.\n",
    "\n",
    "csvDF.loc[:,\"totlA\"] = 18 # Oops, a mistake! Let's get rid of it.\n",
    "csvDF.drop(columns=[\"totlA\"], inplace = True) # The 'inplace' parameter saves the change onto the current object rather than returning.\n",
    "\n",
    "csvDF.loc[:,\"Zero\"] = 0\n",
    "csvDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Manipulation\n",
    "Let's try importing a really big data file.\n",
    "We can use DF.head() in order to print the first few entries.\n",
    "\n",
    "`sales-full.csv` is a massive spreadsheet containing (dummy) data for six separate business men, and how much product they sold on each day.<br />\n",
    "Let's how big this data set *really* is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the data into a DataFrame.\n",
    "salesDF = pd.read_csv(\"sales-full.csv\")\n",
    "\n",
    "# Check the shape (row x col)\n",
    "print(\"Size of sales-full: \" + str(salesDF.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of showing all 300 entries, we can just preview some of the contents with head(), tail(), and/or sample()\n",
    "# You can pass an int argument to increase/decrease the entries shown. (Default 5)\n",
    "x = 5\n",
    "\n",
    "# Show the first x entries.\n",
    "#salesDF.head(x)\n",
    "\n",
    "# Show the last x entries.\n",
    "#salesDF.tail(x)\n",
    "\n",
    "# Show x randomly picked entries.\n",
    "salesDF.sample(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's fix up the column names for our data.** There are many ways to do this.<br/>\n",
    "1. We can choose to just label them directly, but that means we have to label ALL of them.\n",
    "2. Alternatively, we can get a copy of the column names, and index the column we want to change.\n",
    "3. Finally, if we know the name of the column and just want to do some tweaking, we can use the built-in column renaming function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "salesDF.columns = [\"Day\", \"Alex\", \"Bruce\", \"Candice\", \"Denise\", \"Edel\", \"Frisk\"]\n",
    "salesDF.head(5)\n",
    "\n",
    "# Method 2\n",
    "salesDFColumns = salesDF.columns.values; # Produces a numpy array.\n",
    "indexOfCandice = list(salesDFColumns).index(\"Candice\") # Produces an ndarray, so we have to convert it to a list first, then get the index.\n",
    "salesDFColumns[indexOfCandice] = \"Carrie\"\n",
    "salesDF.head(5)\n",
    "\n",
    "# Method 3\n",
    "# We specify the previous name, and then the new name.\n",
    "# The 'inplace' parameter ensures we get a new dataframe with the changes made.\n",
    "salesDF.rename(columns = {'Bruce':'Brandon'}, inplace = True)\n",
    "salesDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's aggregate the data into a new column.**<br/>\n",
    "This is a really big file, so we can't afford to do the math and manually insert it one by one.\n",
    "This is where pandas come into play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the row (nothing), and the column (Total).\n",
    "# If the column doesn't exist, the DataFrame will create a new one and initialize it with the values.\n",
    "salesDF.loc[:,\"Day Total\"] = 0\n",
    "\n",
    "salesDFShape = salesDF.shape\n",
    "print(\"Shape of salesDF = \",salesDFShape)\n",
    "salesDFColumns = salesDF.columns.values;\n",
    "\n",
    "# For every row in salesDF...\n",
    "for i in range(0, salesDFShape[0]):\n",
    "    # Reset the total count.\n",
    "    totalRowVal = 0\n",
    "    # And for every column after 'Day'\n",
    "    for j in salesDFColumns[1:]:\n",
    "        # Aggregate the total across all sellers.\n",
    "        totalRowVal += salesDF.at[i,j]\n",
    "    # And then save into the Day Total column for that row.\n",
    "    salesDF.at[i,\"Day Total\"] = totalRowVal\n",
    "    \n",
    "salesDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualizing Data\n",
    "Now, we can try visualizing the data using matplotlib (plt).\n",
    "matplotlib and pandas play well with each other, and as a result, we can visualize things in multiple ways.\n",
    "More advanced stuff can always be done with `matplotlib.pyplot`, which also supports DataFrames.\n",
    "\n",
    "We'll showcase a few ways of visualizing our Seller-Day data, as well as some context to what these visualizations are typically suitable for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms**<br/>\n",
    "Histograms represent your data exactly as is based on a measure.<br/>\n",
    "They look similar to bar graphs, but differ in that the data isn't 'categorized'.<br/>\n",
    "Visually, this means the bars are connected to each other, as opposed to having some empty space between each other.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesDF.plot(kind='hist', x='Day', y='Day Total', figsize=(5,5))\n",
    "\n",
    "# Another way to plot a histogram.\n",
    "#salesDF[['Day Total']].hist(grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the 'Kernel Density Estimation' plot as another way to represent the distribution of data by probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesDF.plot(kind='kde', x='Day', y='Day Total', figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bar Graph**<br/>\n",
    "We can use bar graphs to represent values in particular categories (qualitative data).<br/>\n",
    "For example, we'll view the results of the first 10 days, and then the results of a particular seller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesDFColumns = salesDF.columns.values;\n",
    "\n",
    "# Total sales for the first 10 days. Let the graph be an 8in x 8in graph.\n",
    "salesDF[:10].plot(kind='bar', x='Day', y='Day Total', figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matplotlib.org/api/axes_api.html?highlight=matplotlib%20axes%20axes#module-matplotlib.axes\n",
    "\n",
    "# We can also turn it into a stacked bar-graph in order to see the breakdowns of each seller.\n",
    "# You can also optionally store the result of plot in order to add axis labels.\n",
    "salesBarA = salesDF[:10].plot(kind='bar', x='Day', y='Alex', figsize=(6,6))\n",
    "salesBarA.set_xlabel(\"Days\")\n",
    "salesBarA.set_ylabel(\"Alex's Daily Sales\")\n",
    "\n",
    "# Hardcoded label. (Bad idea.)\n",
    "#salesBarA.text(x=-0.2, y=330, s='320')\n",
    "\n",
    "# Automated by annotating each bar (patch) in the graph.\n",
    "# Needs alignment.\n",
    "for x in salesBarA.patches:\n",
    "    salesBarA.annotate(str(x.get_height()), (x.get_x(), x.get_height() * 1.020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesDFColumns = salesDF.columns.values;\n",
    "\n",
    "# Total sales for the first 10 days. Let the graph be a 6in x 6in stacked bar graph.\n",
    "salesDF[:10].plot(kind='bar', x='Day Total', y=salesDFColumns[1:7], figsize=(6,6), rot=0, stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart. We can also change the colour-palette using the 'colormap' parameter.\n",
    "# Set1/2 sucks.\n",
    "salesDF[:10].plot(kind='pie', title=\"First 10 Days of Sales\", y='Day Total', figsize=(8,8), fontsize=15, colormap=\"tab10\")\n",
    "\n",
    "#https://matplotlib.org/users/colormaps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Area/Density Graphs**<br/>\n",
    "Area/Density graphs are great for quantitative/numbers-based data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we can also do a density/area plot. (Useful for quantitative/numbers-based data.)\n",
    "# We can see that Denise and Alex made up the majority of sales on Day 10 here too.\n",
    "salesDF[:10].plot(kind='area', x='Day', y=salesDFColumns[1:7], figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation-based Graphing**<br/>\n",
    "While our data doesn't have any correlations (randomly generated), density and scatter plots are a good way to look for correlations between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot.\n",
    "salesDF.plot(kind='scatter', x='Day Total', y='Day', figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hex Plot\n",
    "salesDF.plot(kind='hexbin', x='Day', y='Day Total', gridsize=(20,20), figsize=(8,8), colormap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line Graph (Spaghetti Plot)**<br/>\n",
    "A spaghetti plot overlays multiple lines of sales.<br/>\n",
    "Spaghetti plots are great to showcase performances between Sellers, but can easily become unreadable without proper effort done to highlight particular insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib has multiple visual palettes/styles to use in order to change the way your graphs look.\n",
    "# Seaborn is another visualizer with more aesthetically pleasing palettes.\n",
    "print(\"Matplotlib Available Styles:\\n\",plt.style.available)\n",
    "salesDF[:10].plot(figsize=(8,8), y=salesDFColumns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib's example of multiple spaghetti graphs as a reference.\n",
    "# https://python-graph-gallery.com/125-small-multiples-for-line-chart/\n",
    "# https://matplotlib.org/gallery/color/colormap_reference.html\n",
    "plt.style.use('seaborn-darkgrid') # Pick a style available through matplotlib to make out graph look nice.\n",
    "palette = plt.get_cmap('tab10') # Pick the color set of lines.\n",
    "salesDFShape = salesDF.shape # Get the number of rows/cols.\n",
    "plt.figure(figsize=(10,8)) # Set the figure size\n",
    "\n",
    "\n",
    "num = 0\n",
    "for column in salesDFColumns[1:salesDFShape[1]-1]:\n",
    "    # Set up the subplots.\n",
    "    num += 1\n",
    "    plt.subplot(2,3,num)   \n",
    "    # Plot the shadows of everything else. Also make them thin and light so they don't get in the way.\n",
    "    for v in salesDFColumns[1:salesDFShape[1]-1]:\n",
    "        plt.plot(salesDF['Day'], salesDF[v], marker='', color='grey', linewidth=0.6, alpha=0.3)\n",
    "    \n",
    "    # Plot the coloured line, and set graph's x/y limits.\n",
    "    plt.plot(salesDF['Day'], salesDF[column], marker='', linewidth=1.9, alpha=0.9, color=palette(num)) \n",
    "    plt.xlim(0,10) # 10 Days\n",
    "    plt.ylim(0,1000) # Y-Axis that goes up to 1000 sales.\n",
    "    plt.title(s=salesDFColumns[num], loc='left', fontsize=15, color=palette(num)) # Title the subplot with the seller's name.\n",
    "    \n",
    "    # Remove some of the x/y axis so that they're only in the far left/bottom.\n",
    "    if num in range(4):\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if num not in [1,4,7]:\n",
    "        plt.tick_params(labelleft=False)\n",
    "        \n",
    "# Super Title\n",
    "plt.suptitle(\"Sales each Seller generated in the first 10 days.\", fontsize=20, color='black', style='italic')\n",
    " \n",
    "# Labeled Axis (Hard-coded.)\n",
    "plt.text(-7, -150, 'Days', ha='center', va='center', fontsize=18)\n",
    "plt.text(-26, 1100, 'Sales', ha='center', va='center', rotation='vertical', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Saving Your Work\n",
    "Similar to importing files, `dataFrame.to_fileType(\"fileName.type\")` exporting works for creating a product spreadsheet.\n",
    "\n",
    "Graphs can be downloaded straight out of your notebook by saving the images.\n",
    "\n",
    "Jupyter also supports exporting to a variety of filetypes like `.ipynb` notebooks, `.py` Python files, or `.html` HTML copies of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesDF.to_csv(\"Result1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
